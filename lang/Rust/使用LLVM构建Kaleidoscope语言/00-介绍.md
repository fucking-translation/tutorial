# 使用LLVM & Rust构建Kaleidoscope语言

<h2 align="center">【第一节】：介绍</h2>

</br>

[原文](https://github.com/jauhien/iron-kaleidoscope)

</br>

> 这篇文章介绍了如何使用 LLVM 和 Rust 实现一个简单的编程语言。它的首要目的是展示如何使用 LLVM 创建一个简单的 REPL，因此假定你已经学过了 Rust 的相关知识。说实话，我自己也是 LLVM 和 Rust 新手，所以如果你有任何的反馈意见我都将十分感谢。

仓库中的代码与上一章结束时程序的状态相对应，可以作为下一章节代码开发的起点。

如果你想查看指定章节对应的代码，请查看`chapters`目录。每章都附有相关代码的链接(WIP)。

如果要尝试此仓库中的代码，你需要：

* 最新的 Rust 编译器

* Cargo - Rust 包管理工具

* LLVM (我用的是3.6版本)

如果要构建代码只需 clone 本仓库并执行：

```shell
cargo build
```

然后你就可以在`target`目录下发现名为`iron-kaleidoscope`的可执行程序。

### Kaleidoscope语言的最初变体

在本教程中我们将使用一门名为 Kaleidoscope 的简单的函数式编程语言。这一节中将会展示它的基本变体。在后面的章节中，我们将一步一步地添加新的特性。

这门语言只有一种类型：64位浮点数( Rust 术语(terminology)中的`f64`)。

该语言的第一个变体是非常受限的，甚至图灵也不完整。它只包含了函数定义(或声明)和一些涉及简单算术运算的函数调用。

示例如下。

算术表达式：

```rust
1 + 2 * (3 - 4);
```

函数定义：

```groovy
def plus(x, y)
    x + y
```

函数调用：

```rust
plus(1, 2)
```

外部的函数声明和调用：

```rust
extern sin(x);

sin(1)
```

在 Kaleidoscope 中，除了定义和声明，所有的语句都是表达式且有对应的值。和 Rust 很像。函数体仅是一个表达式，它的值被返回了。没有显式的使用返回操作符。

我们使用`;`字符表示表达式或定义(声明)的结束。在函数原型/调用中，‘,’ 字符和空格字符等价。使用 ‘#’ 表示注释的开始，直到该行的结束。

变量名由字母开始，可以包含任意的字母和数字。保留关键字目前包括`def`和`extern`。任何非字母数字，非空格，不是 ‘(’，‘)’，‘;’ 和 ‘,’ 的字符都被当作操作数。 

字面意思上的数字是十进制数字的非空序列，可能包含十进制小数点符号。

### 项目结构

为了构建 REPL，我们需要：

* 词法分析器 ([lexer.rs](https://github.com/jauhien/iron-kaleidoscope/blob/master/src/lexer.rs))

* 语法解析器 ([parser.rs](https://github.com/jauhien/iron-kaleidoscope/blob/master/src/parser.rs))

* IR 构建工具 ([builder.rs](https://github.com/jauhien/iron-kaleidoscope/blob/master/src/builder.rs))

* JIT 编译器 ([jitter.rs](https://github.com/jauhien/iron-kaleidoscope/blob/master/src/jitter.rs))

* 驱动 ([driver.rs](https://github.com/jauhien/iron-kaleidoscope/blob/master/src/driver.rs))

我们将使用 [Cargo](http://doc.crates.io/) 作为本项目的构建系统。所有的源码都放在`src`目录下。项目将会由两个 crate：类库和可执行文件。所有的实际功能都在类库中实现，而可执行文件将只解析命令行参数并调用驱动。

[Cargo.toml文件](https://github.com/jauhien/iron-kaleidoscope/blob/master/Cargo.toml) 非常简单。

### 词法分析器

实现词法分析器我们需要使用正则表达式。我们拥有以下类型的token(符号中给定的正则表达式使用Rust的`regex`库进行解析)：

* def 和 extern 关键字 (`def|extern`)

* 标识符 (`\p{Alphabetic}\w*`)

* 数字 (`\d+\.?\d*`)

* 分号 (`;`)

* 小括号 (`\(|\)`)

* 逗号 (`,`)

* 运算符 (`\S`)

对应的枚举如下所示：

```rust
#[derive(PartialEq, Clone, Debug)]
pub enum Token {
    Def,
    Extern,
    Delimiter, //';' character
    OpeningParenthesis,
    ClosingParenthesis,
    Comma,
    Ident(String),
    Number(f64),
    Operator(String)
}
```

请注意，像我们之后使用枚举成员却不带命名空间，需要在模块的最开始添加一些 use 导入语句：

```rust
pub use self::Token::{
    Def,
    Extern,
    Delimiter,
    OpeningParenthesis,
    ClosingParenthesis,
    Comma,
    Ident,
    Number,
    Operator
};
```

在下面，我们不会显式的使用这些 use 导入语句。

我们的解析函数将会接受由输入字符组成的字符串并解析成一个 token 向量。它看起来像这样：

```rust
pub fn tokenize(input: &str) -> Vec<Token> {
    // regex for commentaries (start with #, end with the line end)
    let comment_re = regex!(r"(?m)#.*\n");
    // remove commentaries from the input stream
    let preprocessed = comment_re.replace_all(input, "\n");

    let mut result = Vec::new();

    // regex for token, just union of straightforward regexes for different token types
    // operators are parsed the same way as identifier and separated later
    let token_re = regex!(concat!(
        r"(?P<ident>\p{Alphabetic}\w*)|",
        r"(?P<number>\d+\.?\d*)|",
        r"(?P<delimiter>;)|",
        r"(?P<oppar>\()|",
        r"(?P<clpar>\))|",
        r"(?P<comma>,)|",
        r"(?P<operator>\S)"));

    for cap in token_re.captures_iter(preprocessed.as_str()) {
        let token = if cap.name("ident").is_some() {
            match cap.name("ident").unwrap() {
                "def" => Def,
                "extern" => Extern,
                ident => Ident(ident.to_string())
            }
        } else if cap.name("number").is_some() {
            match cap.name("number").unwrap().parse() {
                Ok(number) => Number(number),
                Err(_) => panic!("Lexer failed trying to parse number")
            }
        } else if cap.name("delimiter").is_some() {
            Delimiter
        } else if cap.name("oppar").is_some() {
            OpeningParenthesis
        } else if cap.name("clpar").is_some() {
            ClosingParenthesis
        } else if cap.name("comma").is_some() {
            Comma
        } else {
            Operator(cap.name("operator").unwrap().to_string())
        };

        result.push(token)
    }

    result
}
```

函数十分简单，关于 Rust 中的正则表达式你可以参阅 [regex](http://doc.rust-lang.org/regex/).

一些提醒：我们创建不同组的正则表达式以匹配不同类型的 token。然后我们将其匹配输入的字符串并遍历捕获的值，查看我们匹配了什么样的 token。在相同的正则表达式中，标识符与关键字相匹配，因为它们都有相同的微语法。在后面将使用额外的匹配使它们独立开来。

为了使用这个词法分析器进行测试，你可以创建一个简单的 main 函数，一步步的读取输入的每一行并显示识别的 token。这一节的全部代码可以在[这里](https://github.com/jauhien/iron-kaleidoscope/tree/master/chapters/0)获取，因为这是从完整代码中自动生成的，所以略微有点复杂。